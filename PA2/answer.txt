1) explain how to count bigrams and figure out how many map tasks are launched in the
map stage:


Bigrams:
I actually ran into a lot of trouble with this part because calling the nextToken() mehod moves the iterator over to the next token. When I called nextToken() twice in the while loop, it resulted in a lot issues with word skipping. I managed to solve this problem using the approach below:

public void map(Object key, Text value, Context context
        ) throws IOException, InterruptedException {
            StringTokenizer itr = new StringTokenizer(value.toString());

            String first = itr.nextToken();
            String second = " ";

            while (itr.hasMoreTokens()) {
                context.write(new Text("1BigramCount"), one);
                second = itr.nextToken();
                word.set(first + " " + second);
//                System.out.println("Word: " + word);
                context.write(word, one);
                first = second;
            }
        }


I stored the first word into a variable called "first", and I initiaize an empty string called "second". Within the while loop, I stored the next token into second by calling the nextToken() method. This is then sent to the framework. Finally, I set the pointer of the string "first" to the pointer of "second". This resolves my issues with words being skipped. 


Map task:
I read the following documentations:

https://github.com/apache/hadoop/blob/release-2.7.3-RC2/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/Mapper.java#L136-L151

https://hadoop.apache.org/docs/stable/api/org/apache/hadoop/mapreduce/Mapper.html

The Hadoop Map-Reduce framework spawns one map task for each InputSplit generated by the InputFormat for the job. The framework first calls setup(org.apache.hadoop.mapreduce.Mapper.Context), followed by map(Object, Object, org.apache.hadoop.mapreduce.Mapper.Context) for each key/value pair in the InputSplit. Finally cleanup(org.apache.hadoop.mapreduce.Mapper.Context) is called. This means that for our input in this assignment, there will be a total of 3 map tasks because there are 3 files. In order to implement a counter, we must modify the setup function. The only way to do that is by overriding that function and modifying the code to include the counter: context.write(new Text("1Map task!"), one);



(2) provide your solution to the number of map tasks

1BigramCount	9386
1Map task!	3




